{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80b8d485",
   "metadata": {},
   "source": [
    "\n",
    "# Tema 8 – Predicción de compradores recurrentes (Online Retail – *Auto*)\n",
    "**Curso:** CC3084 – Data Science (Sem II 2025)  \n",
    "**Equipo:** _Mauricio Lemus - 22461, Alexis Mesias - 22562, Hugo Rivas - 22500_  \n",
    "**Repositorio GitHub:** _[https://github.com/Riv2oo4/Proyecto2_DataScience.git]_  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75bfa93",
   "metadata": {},
   "source": [
    "## 0) Preparación del entorno "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24ce3214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entorno Colab: False\n",
      "kaggle.json presente: False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, sys, io, warnings, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def in_colab():\n",
    "    try:\n",
    "        import google.colab  \n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def kaggle_token_present():\n",
    "    return os.path.exists(os.path.expanduser(\"~/.kaggle/kaggle.json\")) or os.path.exists(\"./kaggle.json\")\n",
    "\n",
    "print(\"Entorno Colab:\", in_colab())\n",
    "print(\"kaggle.json presente:\", kaggle_token_present())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd74481e",
   "metadata": {},
   "source": [
    "## 1) Descargar dataset Online Retail "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cc096ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_PATH existe: False -> No encontrado\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DATA_DIR = \"./data\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "DATA_PATH = os.path.join(DATA_DIR, \"Online Retail.xlsx\")\n",
    "\n",
    "def try_kaggle_download():\n",
    "    try:\n",
    "        import subprocess, shutil, json, os\n",
    "        if os.path.exists(\"./kaggle.json\"):\n",
    "            os.makedirs(os.path.expanduser(\"~/.kaggle\"), exist_ok=True)\n",
    "            shutil.copyfile(\"./kaggle.json\", os.path.expanduser(\"~/.kaggle/kaggle.json\"))\n",
    "            os.chmod(os.path.expanduser(\"~/.kaggle/kaggle.json\"), 0o600)\n",
    "\n",
    "        try:\n",
    "            import kaggle  \n",
    "        except Exception:\n",
    "            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"kaggle\", \"--quiet\"], check=True)\n",
    "\n",
    "        # Descargar y descomprimir\n",
    "        zip_path = os.path.join(DATA_DIR, \"onlineretail.zip\")\n",
    "        subprocess.run([\"kaggle\", \"datasets\", \"download\", \"-d\", \"vijayuv/onlineretail\", \"-p\", DATA_DIR, \"--force\"], check=True)\n",
    "        subprocess.run([\"unzip\", \"-o\", zip_path, \"-d\", DATA_DIR], check=True)\n",
    "        print(\"Descarga Kaggle completa.\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(\"Kaggle no disponible o fallo descarga:\", e)\n",
    "        return False\n",
    "\n",
    "if not os.path.exists(DATA_PATH) and kaggle_token_present():\n",
    "    _ = try_kaggle_download()\n",
    "\n",
    "print(\"DATA_PATH existe:\", os.path.exists(DATA_PATH), \"->\", DATA_PATH if os.path.exists(DATA_PATH) else \"No encontrado\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62cd880",
   "metadata": {},
   "source": [
    "## 2) Subir archivo manualmente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e9b93f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No estás en Colab. Puedes colocar el Excel en ./data con nombre 'Online Retail.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    if in_colab():\n",
    "        try:\n",
    "            from google.colab import files  # type: ignore\n",
    "            print(\"Sube el archivo Excel del dataset (e.g., 'Online Retail.xlsx').\")\n",
    "            uploaded = files.upload()\n",
    "            # Guardar con nombre estándar si el usuario sube algo\n",
    "            for name, data in uploaded.items():\n",
    "                with open(DATA_PATH, \"wb\") as f:\n",
    "                    f.write(data)\n",
    "            print(\"Archivo guardado en:\", DATA_PATH)\n",
    "        except Exception as e:\n",
    "            print(\"Subida manual no disponible:\", e)\n",
    "    else:\n",
    "        print(\"No estás en Colab. Puedes colocar el Excel en ./data con nombre 'Online Retail.xlsx'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c78816d",
   "metadata": {},
   "source": [
    "## 3) Cargar datos (o crear sintético si no hay archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ecf9d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dataset sintético para ejecutar el flujo completo.\n",
      "Sintético generado: (2889, 5)\n",
      "Preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>invoice_no</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>invoice_date</th>\n",
       "      <th>quantity</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-18</td>\n",
       "      <td>1</td>\n",
       "      <td>6.85</td>\n",
       "      <td>6.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-03-05</td>\n",
       "      <td>3</td>\n",
       "      <td>10.03</td>\n",
       "      <td>30.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-04-27</td>\n",
       "      <td>2</td>\n",
       "      <td>27.51</td>\n",
       "      <td>55.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-09-09</td>\n",
       "      <td>1</td>\n",
       "      <td>21.77</td>\n",
       "      <td>21.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2025-05-22</td>\n",
       "      <td>5</td>\n",
       "      <td>6.23</td>\n",
       "      <td>31.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  invoice_no  customer_id invoice_date  quantity  unit_price  amount\n",
       "0          1            1   2024-12-18         1        6.85    6.85\n",
       "1          2            1   2024-03-05         3       10.03   30.09\n",
       "2          3            2   2025-04-27         2       27.51   55.02\n",
       "3          4            3   2024-09-09         1       21.77   21.77\n",
       "4          5            3   2025-05-22         5        6.23   31.15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invoice_no              object\n",
      "customer_id              int64\n",
      "invoice_date    datetime64[ns]\n",
      "quantity                 int64\n",
      "unit_price             float64\n",
      "amount                 float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd, numpy as np\n",
    "\n",
    "df = None\n",
    "if os.path.exists(DATA_PATH):\n",
    "    try:\n",
    "        df = pd.read_excel(DATA_PATH)\n",
    "        print(\"Cargado Excel:\", DATA_PATH, \"->\", df.shape)\n",
    "    except Exception as e:\n",
    "        print(\"Error al leer Excel, se usará dataset sintético:\", e)\n",
    "\n",
    "if df is None:\n",
    "    # ---- Synthetic fallback (guaranteed to run) ----\n",
    "    print(\"Usando dataset sintético para ejecutar el flujo completo.\")\n",
    "    rng = np.random.default_rng(42)\n",
    "    n_customers = 1500\n",
    "    start = pd.Timestamp(\"2024-01-01\")\n",
    "    end = pd.Timestamp(\"2025-08-31\")\n",
    "    days = (end - start).days + 1\n",
    "\n",
    "    customers = pd.DataFrame({\n",
    "        \"CustomerID\": np.arange(1, n_customers+1),\n",
    "        \"Channel\": rng.choice([\"web\",\"app\",\"marketplace\"], size=n_customers, p=[0.5,0.4,0.1]),\n",
    "        \"Device\": rng.choice([\"mobile\",\"desktop\",\"tablet\"], size=n_customers, p=[0.6,0.35,0.05]),\n",
    "    })\n",
    "\n",
    "    orders_per_cust = rng.poisson(lam=1.6, size=n_customers) + (rng.random(n_customers) < 0.25)\n",
    "    orders_per_cust = orders_per_cust.astype(int)\n",
    "    orders_per_cust[orders_per_cust<1] = 1\n",
    "\n",
    "    rows = []\n",
    "    order_id = 1\n",
    "    for cid, k in zip(customers[\"CustomerID\"].values, orders_per_cust):\n",
    "        for _ in range(k):\n",
    "            d = start + pd.to_timedelta(rng.integers(0, days), unit=\"D\")\n",
    "            qty = int(max(1, rng.poisson(2)))\n",
    "            price = float(max(1.0, np.round(rng.gamma(shape=2.2, scale=5.0), 2)))\n",
    "            rows.append([str(order_id), str(cid), d, qty, price])\n",
    "            order_id += 1\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=[\"InvoiceNo\",\"CustomerID\",\"InvoiceDate\",\"Quantity\",\"UnitPrice\"])\n",
    "    print(\"Sintético generado:\", df.shape)\n",
    "\n",
    "# Renombrar columnas a snake_case y crear 'amount'\n",
    "rename_map = {\n",
    "    \"InvoiceNo\": \"invoice_no\",\n",
    "    \"StockCode\": \"stock_code\",\n",
    "    \"Description\": \"description\",\n",
    "    \"Quantity\": \"quantity\",\n",
    "    \"InvoiceDate\": \"invoice_date\",\n",
    "    \"UnitPrice\": \"unit_price\",\n",
    "    \"CustomerID\": \"customer_id\",\n",
    "    \"Country\": \"country\",\n",
    "}\n",
    "df = df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns})\n",
    "\n",
    "df[\"invoice_date\"] = pd.to_datetime(df[\"invoice_date\"], errors=\"coerce\")\n",
    "df[\"quantity\"] = pd.to_numeric(df[\"quantity\"], errors=\"coerce\")\n",
    "df[\"unit_price\"] = pd.to_numeric(df[\"unit_price\"], errors=\"coerce\")\n",
    "df[\"customer_id\"] = pd.to_numeric(df[\"customer_id\"], errors=\"coerce\")\n",
    "df[\"amount\"] = df.get(\"quantity\", 1) * df.get(\"unit_price\", 1.0)\n",
    "\n",
    "print(\"Preview:\")\n",
    "display(df.head(5))\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357382ee",
   "metadata": {},
   "source": [
    "## 4) Chequeos iniciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0911f06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nulos por columna:\n",
      "invoice_no      0\n",
      "customer_id     0\n",
      "invoice_date    0\n",
      "quantity        0\n",
      "unit_price      0\n",
      "amount          0\n",
      "dtype: int64\n",
      "\n",
      "Rango de fechas:\n",
      "2024-01-01 00:00:00 -> 2025-08-31 00:00:00\n",
      "\n",
      "'amount' describe:\n",
      "count    2889.000000\n",
      "mean       23.696521\n",
      "std        23.947118\n",
      "min         1.000000\n",
      "25%         8.260000\n",
      "50%        16.120000\n",
      "75%        30.300000\n",
      "max       280.000000\n",
      "Name: amount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Nulos por columna:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "if \"invoice_date\" in df.columns:\n",
    "    print(\"\\nRango de fechas:\")\n",
    "    print(df[\"invoice_date\"].min(), \"->\", df[\"invoice_date\"].max())\n",
    "\n",
    "if \"amount\" in df.columns:\n",
    "    print(\"\\n'amount' describe:\")\n",
    "    print(df[\"amount\"].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e74a60",
   "metadata": {},
   "source": [
    "## 5) Limpieza básica y agregación por orden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53139ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Órdenes únicas: 2889\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>invoice_date</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-18</td>\n",
       "      <td>6.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2024-10-16</td>\n",
       "      <td>29.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>52</td>\n",
       "      <td>2025-08-05</td>\n",
       "      <td>21.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>514</td>\n",
       "      <td>2025-02-05</td>\n",
       "      <td>48.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>515</td>\n",
       "      <td>2025-06-13</td>\n",
       "      <td>33.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  order_id  customer_id invoice_date  amount\n",
       "0        1            1   2024-12-18    6.85\n",
       "1       10            6   2024-10-16   29.52\n",
       "2      100           52   2025-08-05   21.26\n",
       "3     1000          514   2025-02-05   48.15\n",
       "4     1001          515   2025-06-13   33.04"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "data = df.copy()\n",
    "\n",
    "# Filtrar notas de crédito si existen (InvoiceNo que empieza con 'C')\n",
    "if \"invoice_no\" in data.columns:\n",
    "    mask_credit = data[\"invoice_no\"].astype(str).str.startswith(\"C\", na=False)\n",
    "    data = data[~mask_credit].copy()\n",
    "\n",
    "# Filtrar cantidades y precios válidos\n",
    "for col in [\"quantity\",\"unit_price\",\"customer_id\",\"invoice_date\"]:\n",
    "    if col in data.columns:\n",
    "        pass\n",
    "data = data[(data.get(\"quantity\", 1) > 0) & (data.get(\"unit_price\", 1.0) > 0)]\n",
    "data = data.dropna(subset=[\"customer_id\",\"invoice_date\"])\n",
    "\n",
    "# Definir order_id y agrupar\n",
    "data[\"order_id\"] = data.get(\"invoice_no\", data.index.astype(str))\n",
    "orders = (\n",
    "    data.groupby([\"order_id\", \"customer_id\", \"invoice_date\"], as_index=False)\n",
    "        .agg(amount=(\"amount\",\"sum\"))\n",
    ")\n",
    "print(\"Órdenes únicas:\", len(orders))\n",
    "display(orders.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae64c36",
   "metadata": {},
   "source": [
    "# Parte 2 Resultados Iniciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29a585ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (891, 10) Test: (1256, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>recency_days</th>\n",
       "      <th>frequency</th>\n",
       "      <th>monetary_sum</th>\n",
       "      <th>monetary_avg</th>\n",
       "      <th>ipd_mean</th>\n",
       "      <th>ipd_std</th>\n",
       "      <th>ipd_med</th>\n",
       "      <th>cohort_month</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "      <td>1</td>\n",
       "      <td>30.09</td>\n",
       "      <td>30.09</td>\n",
       "      <td>184.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>2024-03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>176</td>\n",
       "      <td>1</td>\n",
       "      <td>13.55</td>\n",
       "      <td>13.55</td>\n",
       "      <td>176.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>2024-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>64.71</td>\n",
       "      <td>64.71</td>\n",
       "      <td>62.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2024-07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.99</td>\n",
       "      <td>12.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>16.23</td>\n",
       "      <td>16.23</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2024-06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  recency_days  frequency  monetary_sum  monetary_avg  ipd_mean  \\\n",
       "0            1           184          1         30.09         30.09     184.0   \n",
       "1            4           176          1         13.55         13.55     176.0   \n",
       "2            5            62          1         64.71         64.71      62.0   \n",
       "3            7             0          1         12.99         12.99       0.0   \n",
       "4           11            82          1         16.23         16.23      82.0   \n",
       "\n",
       "   ipd_std  ipd_med cohort_month  y  \n",
       "0    184.0    184.0      2024-03  1  \n",
       "1    176.0    176.0      2024-03  0  \n",
       "2     62.0     62.0      2024-07  0  \n",
       "3      0.0      0.0      2024-09  0  \n",
       "4     82.0     82.0      2024-06  0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "# Usamos las órdenes ya agregadas en la parte anterior\n",
    "orders = orders.copy()\n",
    "orders['invoice_date'] = pd.to_datetime(orders['invoice_date'])\n",
    "\n",
    "# Horizonte de predicción (días hacia adelante para ver si recompra)\n",
    "HORIZON_DAYS = 180\n",
    "\n",
    "max_date = orders['invoice_date'].max()\n",
    "test_ref  = max_date - pd.Timedelta(days=HORIZON_DAYS)\n",
    "train_ref = test_ref - pd.Timedelta(days=HORIZON_DAYS)\n",
    "\n",
    "def make_features(trans, ref_date):\n",
    "    \"\"\"\n",
    "    Construye variables RFM + IPD + cohorte por cliente, \n",
    "    usando solo el historial hasta ref_date.\n",
    "    \"\"\"\n",
    "    hist = trans[trans['invoice_date'] <= ref_date].copy()\n",
    "\n",
    "    # R (recency), F (frequency), M (monetario)\n",
    "    last_dt  = hist.groupby('customer_id')['invoice_date'].max()\n",
    "    recency  = (ref_date - last_dt).dt.days.rename('recency_days')\n",
    "    freq     = hist.groupby('customer_id').size().rename('frequency')\n",
    "    mon_sum  = hist.groupby('customer_id')['amount'].sum().rename('monetary_sum')\n",
    "    mon_avg  = hist.groupby('customer_id')['amount'].mean().rename('monetary_avg')\n",
    "\n",
    "    # IPD (interpurchase days) – media, desviación, mediana\n",
    "    def ipd_stats(g):\n",
    "        d = g.sort_values('invoice_date')['invoice_date'].diff().dropna().dt.days\n",
    "        return pd.Series({\n",
    "            'ipd_mean': d.mean()   if len(d) else np.nan,\n",
    "            'ipd_std' : d.std()    if len(d) else np.nan,\n",
    "            'ipd_med' : d.median() if len(d) else np.nan\n",
    "        })\n",
    "\n",
    "    ipd = hist.groupby('customer_id').apply(ipd_stats)\n",
    "\n",
    "    # Cohorte: mes de primera compra\n",
    "    first_dt   = hist.groupby('customer_id')['invoice_date'].min()\n",
    "    coh_month  = first_dt.dt.to_period('M').astype(str).rename('cohort_month')\n",
    "\n",
    "    # Unimos todo\n",
    "    feats = pd.concat([recency, freq, mon_sum, mon_avg, ipd, coh_month], axis=1).reset_index()\n",
    "\n",
    "    # Rellenar faltantes razonables\n",
    "    for c in ['ipd_mean', 'ipd_std', 'ipd_med']:\n",
    "        feats[c] = feats[c].fillna(feats['recency_days'])\n",
    "    feats = feats.fillna({\n",
    "        'monetary_sum': 0.0,\n",
    "        'monetary_avg': 0.0,\n",
    "        'frequency': 0,\n",
    "        'recency_days': (ref_date - trans['invoice_date'].min()).days\n",
    "    })\n",
    "\n",
    "    return feats\n",
    "\n",
    "def make_labels(trans, ref_date, horizon_days=HORIZON_DAYS):\n",
    "    \"\"\"\n",
    "    y = 1 si el cliente recompra en la ventana futura\n",
    "    (ref_date, ref_date + horizon], 0 en caso contrario.\n",
    "    \"\"\"\n",
    "    future = trans[\n",
    "        (trans['invoice_date'] > ref_date) &\n",
    "        (trans['invoice_date'] <= ref_date + pd.Timedelta(days=horizon_days))\n",
    "    ]\n",
    "    y1 = pd.Series(1, index=future['customer_id'].unique(), name='y').to_frame()\n",
    "    y1.index.name = 'customer_id'\n",
    "    return y1.reset_index()\n",
    "\n",
    "def build_dataset(trans, ref_date, horizon_days=HORIZON_DAYS):\n",
    "    X = make_features(trans, ref_date)\n",
    "    y = make_labels(trans, ref_date, horizon_days)\n",
    "    data = X.merge(y, how='left', on='customer_id')\n",
    "    data['y'] = data['y'].fillna(0).astype(int)\n",
    "    return data\n",
    "\n",
    "# Datasets de entrenamiento y prueba (split temporal)\n",
    "train_df = build_dataset(orders, train_ref, HORIZON_DAYS)\n",
    "test_df  = build_dataset(orders, test_ref,  HORIZON_DAYS)\n",
    "\n",
    "print(\"Train:\", train_df.shape, \"Test:\", test_df.shape)\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "379abc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, brier_score_loss\n",
    "\n",
    "# Columnas numéricas y categóricas\n",
    "num_cols = ['recency_days','frequency','monetary_sum','monetary_avg',\n",
    "            'ipd_mean','ipd_std','ipd_med']\n",
    "cat_cols = ['cohort_month']\n",
    "\n",
    "train_df['cohort_month'] = train_df['cohort_month'].astype(str).fillna('NA')\n",
    "test_df['cohort_month']  = test_df['cohort_month'].astype(str).fillna('NA')\n",
    "\n",
    "X_train = train_df[num_cols + cat_cols].copy()\n",
    "y_train = train_df['y'].astype(int).values\n",
    "X_test  = test_df[num_cols + cat_cols].copy()\n",
    "y_test  = test_df['y'].astype(int).values\n",
    "\n",
    "# Preprocesamiento: imputar y one-hot\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([\n",
    "            (\"imp\", SimpleImputer(strategy=\"median\"))\n",
    "        ]), num_cols),\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "        ]), cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a96de7b",
   "metadata": {},
   "source": [
    "## Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab4478a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'Logistic+Cal',\n",
       " 'roc_auc': 0.5260365167581574,\n",
       " 'pr_auc': 0.3496300299027636,\n",
       " 'brier': 0.2283826803019739}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "logit = Pipeline(steps=[\n",
    "    (\"pre\", pre),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        max_iter=2000,\n",
    "        class_weight=\"balanced\",\n",
    "        solver=\"lbfgs\"\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Calibrar probabilidades\n",
    "logit_cal = CalibratedClassifierCV(logit, method=\"isotonic\", cv=3)\n",
    "logit_cal.fit(X_train, y_train)\n",
    "\n",
    "# Probabilidades de recompra\n",
    "p_logit = logit_cal.predict_proba(X_test)[:, 1]\n",
    "\n",
    "res_logit = {\n",
    "    \"model\": \"Logistic+Cal\",\n",
    "    \"roc_auc\": roc_auc_score(y_test, p_logit),\n",
    "    \"pr_auc\":  average_precision_score(y_test, p_logit),\n",
    "    \"brier\":   brier_score_loss(y_test, p_logit)\n",
    "}\n",
    "res_logit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e474f791",
   "metadata": {},
   "source": [
    "#LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21c7ba79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\Alexis Mesias\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip -q install lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea1699b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 324, number of negative: 567\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000338 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1427\n",
      "[LightGBM] [Info] Number of data points in the train set: 891, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.363636 -> initscore=-0.559616\n",
      "[LightGBM] [Info] Start training from score -0.559616\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.513803\tvalid_0's binary_logloss: 0.639898\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': 'LightGBM',\n",
       " 'best_iter': 2,\n",
       " 'roc_auc': 0.5138031754691034,\n",
       " 'pr_auc': 0.3468022624157348,\n",
       " 'brier': 0.22381415852810818}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# Ajustar el preprocesador una vez\n",
    "pre_fitted = pre.fit(X_train, y_train)\n",
    "Xtr = pre_fitted.transform(X_train)\n",
    "Xte = pre_fitted.transform(X_test)\n",
    "\n",
    "clf_lgb = lgb.LGBMClassifier(\n",
    "    objective=\"binary\",\n",
    "    n_estimators=10000,          # muchos árboles + early stopping\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=63,\n",
    "    min_data_in_leaf=100,\n",
    "    feature_fraction=0.8,\n",
    "    subsample=0.9,\n",
    "    subsample_freq=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "clf_lgb.fit(\n",
    "    Xtr, y_train,\n",
    "    eval_set=[(Xte, y_test)],\n",
    "    eval_metric=\"auc\",\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=200),\n",
    "        lgb.log_evaluation(0)\n",
    "    ]\n",
    ")\n",
    "\n",
    "p_lgbm = clf_lgb.predict_proba(Xte)[:, 1]\n",
    "\n",
    "res_lgbm = {\n",
    "    \"model\": \"LightGBM\",\n",
    "    \"best_iter\": int(getattr(clf_lgb, \"best_iteration_\", clf_lgb.n_estimators)),\n",
    "    \"roc_auc\": float(roc_auc_score(y_test, p_lgbm)),\n",
    "    \"pr_auc\":  float(average_precision_score(y_test, p_lgbm)),\n",
    "    \"brier\":   float(brier_score_loss(y_test, p_lgbm)),\n",
    "}\n",
    "res_lgbm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d845804",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a759f233",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\Alexis Mesias\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip -q install catboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17e44e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'CatBoost',\n",
       " 'roc_auc': 0.5312702444679327,\n",
       " 'pr_auc': 0.3724490268028136,\n",
       " 'brier': 0.24675608082977912}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "X_train_cb = train_df[num_cols + cat_cols].copy()\n",
    "X_test_cb  = test_df[num_cols + cat_cols].copy()\n",
    "\n",
    "for c in cat_cols:\n",
    "    X_train_cb[c] = X_train_cb[c].astype('category').cat.add_categories(['NA']).fillna('NA')\n",
    "    X_test_cb[c]  = X_test_cb[c].astype('category').cat.add_categories(['NA']).fillna('NA')\n",
    "\n",
    "y_train_cb = train_df['y'].astype(int).values\n",
    "y_test_cb  = test_df['y'].astype(int).values\n",
    "\n",
    "cat_idx = [X_train_cb.columns.get_loc(c) for c in cat_cols]\n",
    "\n",
    "cb = CatBoostClassifier(\n",
    "    loss_function=\"Logloss\",\n",
    "    eval_metric=\"AUC\",\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    iterations=500,\n",
    "    random_seed=42,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "cb.fit(\n",
    "    X_train_cb, y_train_cb,\n",
    "    eval_set=(X_test_cb, y_test_cb),\n",
    "    cat_features=cat_idx\n",
    ")\n",
    "\n",
    "p_cb = cb.predict_proba(X_test_cb)[:, 1]\n",
    "\n",
    "res_cb = {\n",
    "    \"model\": \"CatBoost\",\n",
    "    \"roc_auc\": roc_auc_score(y_test_cb, p_cb),\n",
    "    \"pr_auc\":  average_precision_score(y_test_cb, p_cb),\n",
    "    \"brier\":   brier_score_loss(y_test_cb, p_cb)\n",
    "}\n",
    "res_cb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc4e1ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>pr_auc</th>\n",
       "      <th>brier</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.531270</td>\n",
       "      <td>0.372449</td>\n",
       "      <td>0.246756</td>\n",
       "      <td>0.212996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic+Cal</td>\n",
       "      <td>0.526037</td>\n",
       "      <td>0.349630</td>\n",
       "      <td>0.228383</td>\n",
       "      <td>0.098361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.513803</td>\n",
       "      <td>0.346802</td>\n",
       "      <td>0.223814</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model   roc_auc    pr_auc     brier        f1\n",
       "0      CatBoost  0.531270  0.372449  0.246756  0.212996\n",
       "1  Logistic+Cal  0.526037  0.349630  0.228383  0.098361\n",
       "2      LightGBM  0.513803  0.346802  0.223814  0.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Predicciones binarias con umbral 0.5\n",
    "y_pred_logit = (p_logit >= 0.5).astype(int)\n",
    "y_pred_lgbm  = (p_lgbm >= 0.5).astype(int)\n",
    "y_pred_cb    = (p_cb   >= 0.5).astype(int)\n",
    "\n",
    "results = pd.DataFrame([\n",
    "    {\n",
    "        \"model\": res_logit[\"model\"],\n",
    "        \"roc_auc\": res_logit[\"roc_auc\"],\n",
    "        \"pr_auc\":  res_logit[\"pr_auc\"],\n",
    "        \"brier\":   res_logit[\"brier\"],\n",
    "        \"f1\":      f1_score(y_test, y_pred_logit)\n",
    "    },\n",
    "    {\n",
    "        \"model\": res_lgbm[\"model\"],\n",
    "        \"roc_auc\": res_lgbm[\"roc_auc\"],\n",
    "        \"pr_auc\":  res_lgbm[\"pr_auc\"],\n",
    "        \"brier\":   res_lgbm[\"brier\"],\n",
    "        \"f1\":      f1_score(y_test, y_pred_lgbm)\n",
    "    },\n",
    "    {\n",
    "        \"model\": res_cb[\"model\"],\n",
    "        \"roc_auc\": res_cb[\"roc_auc\"],\n",
    "        \"pr_auc\":  res_cb[\"pr_auc\"],\n",
    "        \"brier\":   res_cb[\"brier\"],\n",
    "        \"f1\":      f1_score(y_test_cb, y_pred_cb)\n",
    "    },\n",
    "])\n",
    "\n",
    "results.sort_values(by=\"pr_auc\", ascending=False).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340118fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>pr_auc</th>\n",
       "      <th>brier</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic+Cal</td>\n",
       "      <td>0.526037</td>\n",
       "      <td>0.349630</td>\n",
       "      <td>0.228383</td>\n",
       "      <td>0.098361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.513803</td>\n",
       "      <td>0.346802</td>\n",
       "      <td>0.223814</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.531270</td>\n",
       "      <td>0.372449</td>\n",
       "      <td>0.246756</td>\n",
       "      <td>0.212996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model   roc_auc    pr_auc     brier        f1\n",
       "0  Logistic+Cal  0.526037  0.349630  0.228383  0.098361\n",
       "1      LightGBM  0.513803  0.346802  0.223814  0.000000\n",
       "2      CatBoost  0.531270  0.372449  0.246756  0.212996"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>pr_auc</th>\n",
       "      <th>brier</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic+Cal</th>\n",
       "      <td>0.526037</td>\n",
       "      <td>0.349630</td>\n",
       "      <td>0.228383</td>\n",
       "      <td>0.098361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.513803</td>\n",
       "      <td>0.346802</td>\n",
       "      <td>0.223814</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>0.531270</td>\n",
       "      <td>0.372449</td>\n",
       "      <td>0.246756</td>\n",
       "      <td>0.212996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               roc_auc    pr_auc     brier        f1\n",
       "model                                               \n",
       "Logistic+Cal  0.526037  0.349630  0.228383  0.098361\n",
       "LightGBM      0.513803  0.346802  0.223814  0.000000\n",
       "CatBoost      0.531270  0.372449  0.246756  0.212996"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "display(results)\n",
    "\n",
    "res = results.copy()\n",
    "res[\"model\"] = res[\"model\"].astype(str)\n",
    "res = res.set_index(\"model\")\n",
    "display(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7b264e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.makedirs(\"plots\", exist_ok=True)\n",
    "\n",
    "def plot_metric_bars(df, metric, lower_is_better=False, filename=None, title=None, fmt=\"{:.3f}\"):\n",
    "    series = df[metric].dropna()\n",
    "    if series.empty:\n",
    "        print(f\"No hay datos para la métrica '{metric}'.\")\n",
    "        return\n",
    "    \n",
    "    # Orden: descendente si más alto es mejor; ascendente si más bajo es mejor\n",
    "    series = series.sort_values(ascending=lower_is_better)\n",
    "    \n",
    "    plt.figure()\n",
    "    ax = series.plot(kind=\"bar\")\n",
    "    ax.set_title(title or f\"Comparación por modelo: {metric.upper()}\")\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_xlabel(\"Modelo\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    \n",
    "    # Etiquetas de valo\n",
    "    for p in ax.patches:\n",
    "        value = p.get_height()\n",
    "        ax.annotate(fmt.format(value), \n",
    "                    (p.get_x() + p.get_width()/2, value),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if filename:\n",
    "        plt.savefig(filename, dpi=160, bbox_inches=\"tight\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
